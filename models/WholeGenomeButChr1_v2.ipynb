{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WholeGenomeButChr1_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simecek/PseudoDNA_Generator/blob/master/models/WholeGenomeButChr1_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8NYCcZxvM2P",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeFnR_pcvEED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastai2>=0.0.11 ipywidgets matplotlib nbdev>=0.2.12 pandas scikit_learn sentencepiece biopython"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5IVYhgbuc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1da27288-5130-462f-ae6f-db57df8cabfc"
      },
      "source": [
        "# Mount to your Google Drive allowing lesson files will be saved to your Drive location\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uk2xXFncEb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DNA_TOPLEVEL_FASTA_PATH = \"/content/drive/My Drive/data/ensembl/Homo_sapiens.GRCh38.dna.toplevel.fa.gz\"\n",
        "DNA_TEXT_PATH = \"/content/drive/My Drive/data/Homo_sapiens.GRCh38.dna.chrtext/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1BP7wB4dsUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9b938c2-1f02-4cd1-c319-590e235ef2a2"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.get_device_name(0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 1, 'Tesla P100-PCIE-16GB')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXarDVNotL1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "59b5fa27-dd52-4d79-94d2-899a4962cee9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/simecek/PseudoDNA_Generator/master/models/genomic_tokenizer2.py "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-19 22:31:32--  https://raw.githubusercontent.com/simecek/PseudoDNA_Generator/master/models/genomic_tokenizer2.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 565 [text/plain]\n",
            "Saving to: ‘genomic_tokenizer2.py’\n",
            "\n",
            "\rgenomic_tokenizer2.   0%[                    ]       0  --.-KB/s               \rgenomic_tokenizer2. 100%[===================>]     565  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-19 22:31:33 (38.6 MB/s) - ‘genomic_tokenizer2.py’ saved [565/565]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExfZF-bTvSkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.text.all import *\n",
        "from Bio import SeqIO\n",
        "import pandas as pd\n",
        "import gzip\n",
        "from tqdm.notebook import tqdm\n",
        "from genomic_tokenizer2 import tkn2\n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5llVi05mkYin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e30d5fc-b34b-40a0-c480-d239e048f982"
      },
      "source": [
        "!ls \"/content/drive/My Drive/data/Homo_sapiens.GRCh38.dna.chrtext/\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1   11\t13  15\t17  19\t20  22\t4  6  8  MT  Y\n",
            "10  12\t14  16\t18  2\t21  3\t5  7  9  X\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-WYDE4wvZEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/data\n",
        "!mkdir /content/data\n",
        "!mkdir /content/data/train\n",
        "!mkdir /content/data/valid"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwhLe0S-Yf9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_chrom_sample(chrom, dest_dir, downscale_factor=20):\n",
        "  chunks = os.listdir(DNA_TEXT_PATH + chrom)\n",
        "  N_chunks = len(chunks)\n",
        "  N_selected = math.ceil(N_chunks / downscale_factor)\n",
        "  chunks_selected = random.sample(chunks, N_selected)\n",
        "  os.mkdir(dest_dir + chrom + \"/\")\n",
        "  for chunk in chunks_selected:\n",
        "    shutil.copyfile(DNA_TEXT_PATH + chrom + \"/\" + chunk, dest_dir + chrom + \"/\" + chunk)\n",
        "  print(chrom, N_selected) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-qB59cPxI96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34ff5989-df2a-4d58-bdd4-ed86c1400310"
      },
      "source": [
        "random.seed(42)\n",
        "\n",
        "get_chrom_sample('1', '/content/data/valid/', downscale_factor=5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsGn-JAOz-zk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "33c14edb-56f8-4e81-836c-b26e73c7f011"
      },
      "source": [
        "TRAIN_CHRS = [str(i) for i in range(2,23)] + ['X', 'Y', 'MT']\n",
        "for chrom in TRAIN_CHRS:\n",
        "  get_chrom_sample(chrom, '/content/data/train/', 25)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 97\n",
            "3 80\n",
            "4 77\n",
            "5 73\n",
            "6 69\n",
            "7 64\n",
            "8 59\n",
            "9 56\n",
            "10 54\n",
            "11 55\n",
            "12 54\n",
            "13 40\n",
            "14 37\n",
            "15 34\n",
            "16 37\n",
            "17 34\n",
            "18 33\n",
            "19 24\n",
            "20 26\n",
            "21 17\n",
            "22 17\n",
            "X 63\n",
            "Y 22\n",
            "MT 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dinqfRwPyPiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ff792e82-56d2-4665-a842-5310a46d911c"
      },
      "source": [
        "!ls /content/data/train/Y/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_122.txt  Y_209.txt  Y_261.txt  Y_335.txt  Y_46.txt   Y_56.txt\n",
            "Y_132.txt  Y_216.txt  Y_296.txt  Y_389.txt  Y_498.txt  Y_7.txt\n",
            "Y_140.txt  Y_225.txt  Y_308.txt  Y_404.txt  Y_509.txt\n",
            "Y_179.txt  Y_235.txt  Y_315.txt  Y_440.txt  Y_539.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMNqgj9n1TEw",
        "colab_type": "text"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFgyggiNxlz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls_lm = TextDataLoaders.from_folder(Path(\"/content/data\"), bs=2048, seed=42, \n",
        "                                   is_lm=True, \n",
        "                                   tok_tfm=tkn2, seq_len=50)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmftEQ6bx42-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "f1997d98-3629-4510-b3ae-5e627a736c2b"
      },
      "source": [
        "dls_lm.show_batch()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C A T A C T G T A C A T A A A A T A T C A A A C T A C C C A A A C T A T A T A T T A T A T A C G G T</td>\n",
              "      <td>A T A C T G T A C A T A A A A T A T C A A A C T A C C C A A A C T A T A T A T T A T A T A C G G T A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C T G C A A G T G G A T A T T T G G A T A G C T T T G A G G A T T T C G T T G G A A A C G G G T T A</td>\n",
              "      <td>T G C A A G T G G A T A T T T G G A T A G C T T T G A G G A T T T C G T T G G A A A C G G G T T A T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A T T T T C T T T A T C C A G T C T A T C A T T G A T G G G C A T T T G A G T T G A T A C C A T G T</td>\n",
              "      <td>T T T T C T T T A T C C A G T C T A T C A T T G A T G G G C A T T T G A G T T G A T A C C A T G T A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>G T T T A T A A T A T A T T T G G T A G A A G T T A G C A G T G A A T C C A T C T A G T C C T G G G</td>\n",
              "      <td>T T T A T A A T A T A T T T G G T A G A A G T T A G C A G T G A A T C C A T C T A G T C C T G G G C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T G G C T T T C A C C G T G T T A G C C A G G A T G G T C T C A A A T C T C C T G A C C T C A T G A</td>\n",
              "      <td>G G C T T T C A C C G T G T T A G C C A G G A T G G T C T C A A A T C T C C T G A C C T C A T G A T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>C C T A A T G T T A A T C T C C A A G A C C A T G G G G A A A A T G T C T C C A G G G C A T G T C A</td>\n",
              "      <td>C T A A T G T T A A T C T C C A A G A C C A T G G G G A A A A T G T C T C C A G G G C A T G T C A G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>C A G A G T G A G A C T C T G T C T C A G A A A A A A A C A A A C A A A C A A A C A A A C A A A T A</td>\n",
              "      <td>A G A G T G A G A C T C T G T C T C A G A A A A A A A C A A A C A A A C A A A C A A A C A A A T A A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A A T G C C A T G C A G T C T A A A C A C A T C T G C G C A G A A C A C A G C C C A G G C C A T G C</td>\n",
              "      <td>A T G C C A T G C A G T C T A A A C A C A T C T G C G C A G A A C A C A G C C C A G G C C A T G C A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>C T G A T A A C T T T G G A G A T G G T G A C A T G A G A A T A G A G G A A A A A A A C T T T C A G</td>\n",
              "      <td>T G A T A A C T T T G G A G A T G G T G A C A T G A G A A T A G A G G A A A A A A A C T T T C A G G</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sr_NFaB1uHH",
        "colab_type": "text"
      },
      "source": [
        "## Model and Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcOLVeQk0tJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(\n",
        "    dls_lm, AWD_LSTM, drop_mult=0.3, pretrained=False, \n",
        "    metrics=[accuracy, Perplexity()])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdWkfIiG11dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "37f1bbe5-4243-4dc0-c65b-5b3375b9d391"
      },
      "source": [
        "learn.fit_one_cycle(2, 2e-2)\n",
        "learn.export('/content/drive/My Drive/DNAModels/Human_v0/all_but_chr1_v2.pkl')\n",
        "learn.save('/content/drive/My Drive/DNAModels/Human_v0/all_but_chr1_v2')\n",
        "learn.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.475801</td>\n",
              "      <td>1.278890</td>\n",
              "      <td>0.341241</td>\n",
              "      <td>3.592649</td>\n",
              "      <td>5:17:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.423227</td>\n",
              "      <td>1.241679</td>\n",
              "      <td>0.375350</td>\n",
              "      <td>3.461422</td>\n",
              "      <td>5:05:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN (Input shape: ['2048 x 50'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "RNNDropout           2048 x 50 x 400      0          False     \n",
              "________________________________________________________________\n",
              "RNNDropout           2048 x 50 x 1152     0          False     \n",
              "________________________________________________________________\n",
              "RNNDropout           2048 x 50 x 1152     0          False     \n",
              "________________________________________________________________\n",
              "Linear               2048 x 50 x 8        3,208      True      \n",
              "________________________________________________________________\n",
              "RNNDropout           2048 x 50 x 400      0          False     \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 3,208\n",
              "Total trainable params: 3,208\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f36904e2620>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Model unfrozen\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback\n",
              "  - ModelReseter\n",
              "  - RNNRegularizer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZHDtiwV7OKk",
        "colab_type": "text"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xg2Fdsl6TFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = load_learner('/content/drive/My Drive/DNAModels/Human_v0/all_but_chr1_v2.pkl')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XruSBY7kQ0fm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9dcb13c1-aa70-47b2-ff94-a836d3621ec9"
      },
      "source": [
        "TEXT = \"ACTGCCTGCCTGC\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75)[::2] \n",
        "         for _ in range(N_SENTENCES)]\n",
        "preds"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ACTGCCTGCCTGCCATTGAGTTGTTTGCATTGAGTGGTGTATTATATTCCTGA',\n",
              " 'ACTGCCTGCCTGCTGTTGGGGCCCCCCTACCTTTTAAATCTTGGCCTCTTAAT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}